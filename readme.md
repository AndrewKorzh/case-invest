# Case

Файл в корневой папке проекта
`config.py:`

`db_config` = {   
    "dbname": "xxx",   
    "user": "xxx",     
    "password": "xxx",   
    "host": "xxx",   
    "port": "xxx",    
}

`ARCHIVE_PATH` = "xxx"

`STAGE_SCHEMA_NAME` = "xxx"

`stage_filler.py` - заполнение данными
`stage_former.py` - создание всех таблиц

---

stage_former_no_con - без связей (актуальная версия)
stage_former - со связями

`docker run --name my-postgres -e POSTGRES_PASSWORD=mysecretpassword -d -p 5432:5432 postgres` - простой способ развернуть postgres локально с помощью docker
# Этапы  
Отдельный модуль для создания stage (stage_former.py)
- Нужен для первичной настройки - просто пустые таблички со связями + триггеры + таблицы с логгированием ошибок

Заполнение данными (stage_filler.py)
- цикл по всем табличкам, для каждой процесс идентичный
- В data_structure получили пару ключ-значение - в ней необходимые данные о конкретной табличке
- Проходимся по всем файлам csv в папке (имя указано, путь к архиву черех config) и проверяем (только по первой строчке - быстрый процесс) наличие заголовков, соответствие ожидаемой структуре

| file_path | success | headers |
|----------------|----------------|----------------|
| ...file1.csv    | True     | True     |
| ...file2.csv     | True     | False     |
| ...file3.csv     | False     | False     |

- Создаём временную таблицу, где все столбцы text (без индексов и тд) - она нужна для обработки

- Все успешные файлы через \copy во временную таблицу, неуспешные - записываем в служебную БД
 
- Далее производим вставку данных и удаляем таблицу

# Реестр проверок
- PK - уникальные
- "" -> NULL
- Дата конца не больше даты начала...

# Проверка качества - в витрины
- Сколько записей пропущено
- Какие файлы не были загружены
- Заполненность полей по каждой табличке (можно в виде графика)
- Недопустимые значения - зп < 0 и тд


# Очерёдность
- Создание всех таблиц
- 
# TODO
- Обернуть всё что можно в try exept
- Время ошибки + очищать иногда
- Еще таблица в которой пропущенные записи
- Принимается решение, норм или нет - если что записываем дату и etl 2

- last_actual_data |id|date|
- source - относительный путь сделать (относительно архива)
- Перед полной загрузкой данных можно ошибки очищать

- у пользователя нет несколько подряд идущих enable enable disable disable enable - удаляем то, что не в том порядке
- tail_limit > 0
- disable = 0
- change limit > 0
- уникальность всех id
- create < delt
- округление копилки (сопоставление trans с limit)
- тип счёта сопоставлять с заявкой
- файлики 

- Преобразование типов